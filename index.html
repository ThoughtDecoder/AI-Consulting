<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Thought Decoder</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>

  <header>
    <div><strong>Thought Decoder</strong></div>
    <nav>
      <a href="#services">Services</a>
      <a href="#why-logic">Why Logic?</a>
      <a href="#about">About</a>
      <a href="https://calendly.com/thoughtdecoder" class="btn" target="_blank" rel="noopener noreferrer">Schedule a Call</a>
    </nav>
  </header>

  <div class="hero">
    <h1 style="display: flex; align-items: center; justify-content: center; gap: 10px;">
      Logic Auditing for AI Systems
      <img src="images/logo.png" alt="Thought Decoder Logo" style="height: 40px; vertical-align: middle;" />
    </h1>
    <p>AI products should think as clearly as the people who build them. Thought Decoder applies formal logic and ethical scrutiny to ensure your systems reason consistently, avoid contradiction, and build user trust from the first prompt.</p>
    <a href="#contact"><button class="btn">Schedule a Call</button></a>
  </div>

  <section id="services">
    <h2>Our Services</h2>
    <ul class="services">
      <li><strong>Logic Audit Report:</strong> Analysis of contradictions, flawed inferences, and misused concepts.</li>
      <li><strong>Annotated Outputs:</strong> GPT outputs with embedded comments highlighting logic flaws.</li>
      <li><strong>Recommendations:</strong> Prompt engineering and fine-tuning advice based on findings.</li>
      <li><strong>1-Hour Strategy Session:</strong> Walkthrough of the audit with your product or engineering team.</li>
    </ul>
  </section>

  <section id="why-logic">
    <h2>Why Logic Auditing Matters</h2>
    <ul class="services">
      <li><strong>82% of AI leaders</strong> say unintentional logical errors reduce user trust in their systems. <em>(Source: MIT Sloan)</em></li>
      <li>Companies like OpenAI and Anthropic invest heavily in <strong>alignment and consistency checks</strong> — logic flaws lead to hallucinations, user distrust, and reputational risk.</li>
      <li>Upcoming regulations (EU AI Act, NIST AI RMF) emphasize <strong>transparency and auditability</strong> of reasoning in high-risk AI systems.</li>
    </ul>
  </section>

  <section id="about">
    <h2>About Thought Decoder</h2>
    <p>Founded by Professor Sean Mixon, Thought Decoder brings the power of formal logic and philosophical reasoning into the age of artificial intelligence. With over a decade of experience teaching logic and argument analysis, Sean now helps AI developers and ethics teams ensure their systems make sense — literally.</p>
  </section>

  <section id="contact">
    <h2>Contact Us</h2>
    <p>Email: <a href="mailto:sean@thoughtdecoder.com">sean@thoughtdecoder.com</a></p>
    <p>LinkedIn: <a href="https://www.linkedin.com/in/seanmixon1" target="_blank">Sean Mixon</a></p>
    <p>Schedule: <a href="https://calendly.com/thoughtdecoder" target="_blank">Book a Consultation</a></p>
  </section>

<footer>
  <p>&copy; 2025 Thought Decoder. All rights reserved.</p>
</footer>

</body>
</html>
